<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Topographic Sandbox</title>
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
      scroll-behavior: smooth;
    }

    body {
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      background: #f5f5f5;
      color: #333;
    }

    /* Sticky Nav */
    nav {
      position: sticky;
      top: 0;
      background: linear-gradient(135deg, #ff9999, #ff4d4d);
      padding: 1rem 2rem;
      display: flex;
      justify-content: center;
      gap: 2rem;
      z-index: 1000;
      box-shadow: 0 2px 6px rgba(0, 0, 0, 0.1);
    }

    nav a {
      color: white;
      text-decoration: none;
      font-weight: bold;
      position: relative;
      padding: 0.3rem 0;
      transition: all 0.3s ease;
    }

    nav a::after {
      content: '';
      position: absolute;
      left: 0;
      bottom: 0;
      height: 2px;
      width: 100%;
      background-color: #d4f5e9;
      transform: scaleX(0);
      transform-origin: right;
      transition: transform 0.3s ease;
    }

    nav a:hover {
      transform: scale(1.05);
      color: #d4f5e9;
    }

    nav a:hover::after {
      transform: scaleX(1);
      transform-origin: left;
    }

    nav a.active {
      color: #fffae1;
    }

    header {
      height: 100vh;
      background: url('photos/background.jpg') no-repeat center center;
      background-size: cover;
      color: white;
      display: flex;
      flex-direction: column;
      justify-content: center;
      align-items: center;
      text-align: center;
      padding: 2rem;
    }

    header h1 {
      font-size: 3rem;
      overflow: hidden;
      white-space: nowrap;
      border-right: 3px solid white;
      max-width: 90%;
    }

    @keyframes typing {
      from {
        width: 0;
      }

      to {
        width: 100%;
      }
    }

    @keyframes blink {
      50% {
        border-color: transparent;
      }
    }

    header p {
      font-size: 1.2rem;
      margin-top: 10px;
      opacity: 0;
      transform: translateY(20px);
      animation: fadeInUp 2s ease-out forwards;
      animation-delay: 2s;
    }

    .scroll-down {
      margin-top: 40px;
      font-size: 1.5rem;
      cursor: pointer;
      animation: bounce 2s infinite;
      transition: transform 0.3s;
    }

    .scroll-down:hover {
      transform: scale(1.2);
    }

    section {
      padding: 80px 20px;
      max-width: 900px;
      margin: auto;
    }

    section h2 {
      font-size: 2.2rem;
      margin-bottom: 20px;
      text-align: center;
    }

    section p {
      line-height: 1.6;
      font-size: 1.1rem;
    }

    @keyframes fadeInUp {
      from {
        opacity: 0;
        transform: translateY(30px);
      }

      to {
        opacity: 1;
        transform: translateY(0);
      }
    }

    @keyframes bounce {

      0%,
      100% {
        transform: translateY(0);
      }

      50% {
        transform: translateY(8px);
      }
    }

    /* Handles Section Styling */
    .handles-logos {
      display: flex;
      justify-content: center;
      gap: 3rem;
      margin-top: 30px;
      flex-wrap: wrap;
      opacity: 0;
      transform: translateY(40px);
      transition: opacity 0.6s ease-out, transform 0.6s ease-out;
    }

    .handles-logos.visible {
      opacity: 1;
      transform: translateY(0);
    }

    .handles-logos img {
      width: 140px;
      height: auto;
      border-radius: 16px;
      transition: transform 0.3s ease, box-shadow 0.3s ease;
      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
    }

    .handles-logos a:hover img {
      transform: scale(1.15) rotate(2deg);
      box-shadow: 0 8px 20px rgba(0, 0, 0, 0.2);
    }
  </style>
</head>

<body>

  <!-- Sticky Nav -->
  <nav>
    <a onclick="document.getElementById('Project Objective').scrollIntoView({ behavior: 'smooth' });">
      Project Objective
    </a>
    <a onclick="document.getElementById('video').scrollIntoView({ behavior: 'smooth' });">
      Demo Video
    </a>
    <a onclick="document.getElementById('Introduction').scrollIntoView({ behavior: 'smooth' });">
      Introduction
    </a>
    <a onclick="document.getElementById('Design').scrollIntoView({ behavior: 'smooth' });">
      Design
    </a>
    <a onclick="document.getElementById('Installation Guide').scrollIntoView({ behavior: 'smooth' });">
      Installation Guide
    </a>
    <a onclick="document.getElementById('Testing').scrollIntoView({ behavior: 'smooth' });">
      Testing
    </a>
    <a onclick="document.getElementById('Result').scrollIntoView({ behavior: 'smooth' });">
      Result
    </a>
    <a onclick="document.getElementById('Conclusion').scrollIntoView({ behavior: 'smooth' });">
      Conclusion
    </a>
    <a onclick="document.getElementById('Future Work').scrollIntoView({ behavior: 'smooth' });">
      Future Work
    </a>
    <a onclick="document.getElementById('Budget').scrollIntoView({ behavior: 'smooth' });">
      Budget
    </a>
    <a onclick="document.getElementById('The Team').scrollIntoView({ behavior: 'smooth' });">
      The Team
    </a>
    <a onclick="document.getElementById('References').scrollIntoView({ behavior: 'smooth' });">
      References
    </a>
    <a onclick="document.getElementById('Distribution').scrollIntoView({ behavior: 'smooth' });">
      Distribution
    </a>
    <a onclick="document.getElementById('The Code Listing').scrollIntoView({ behavior: 'smooth' });">
      Code Listing
    </a>
  </nav>

  <!-- Hero / Home Section -->
  <header id="home">
    <h1>Topographic Sandbox</h1>
    <div style="height: 20px;"></div>
    <h2>By: George Maidhof (gpm58) and Giorgi Berndt (gb449) </h2>
    <h2>Date: May 10th 2025</h2>
    <div class="scroll-down" onclick="document.getElementById('video').scrollIntoView({ behavior: 'smooth' });">
      ↓ Project Information
    </div>
  </header>

  <section id="Project Objective">
    <h2>Project Objective</h2>
    <p>
      The goal of this project was to design and build an engaging, interactive sandbox using real-time depth sensing
      and projection.
      Inspired by our childhood experiences, we developed a system that
      encourages user interaction by allowing changes in the sand's shape to be reflected in a dynamic, color-mapped
      projection.
      This project serves as a creative application of concepts learned in class, particularly GPIO control and
      real-time
      data processing with the Raspberry Pi, while also offering a fun demonstration of how physical changes can be
      reflected as inputs and can drive real time changes in a digital
      output in an intuitive and entertaining way.
    </p>
  </section>


  <section id="video" style="padding: 60px 20px; text-align: center;">
    <h2 style="font-size: 2rem; margin-bottom: 20px;">Demo Video</h2>
    <div style="
      display: inline-block;
      background: white;
      border-radius: 16px;
      box-shadow: 0 8px 20px rgba(0, 0, 0, 0.1);
      border: 2px solid #e0e0e0;
      padding: 20px;
      max-width: 600px;
      width: 100%;
    ">
      <iframe width="560" height="315" src="https://www.youtube.com/embed/7OE1gsFn2Js" title="Topographic Sandbox"
        frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
        allowfullscreen style="border-radius: 12px; width: 100%; height: 315px;"></iframe>
    </div>
  </section>


  <section id="Introduction">
    <h2>Introduction</h2>
    <p>
      In this project, we created an interactive topographic sandbox that visualizes real-time topographical data
      using a Microsoft Xbox 360 Kinect, a Raspberry Pi, and a Projector.
      The Kinect captures a continuous stream of depth information, generating 480x640 arrays of Z-values that represent
      the height of the sand surface.
      These depth values are processed in real time and mapped to a dynamic color gradient, simulating elevation-based
      coloration like that found on topographic maps.
      The resulting color map is then projected directly onto the sandbox surface, creating a live, responsive display
      that updates as the sand is moved.
      We also integrated GPIO-controlled buttons on the Raspberry Pi to easily start and stop the system, providing a
      smooth and interactive user experience.
    </p>
  </section>

  <section id="Design">
    <h2>Design</h2>
    <p>
      This project integrates hardware and software components to create a responsive, real-time augmented reality
      sandbox.
      The system is designed to capture live depth data from a Microsoft Xbox 360 Kinect sensor, process it using a
      Raspberry Pi 4, and project a corresponding color-mapped topographic image onto a physical sandbox.
      The primary goal of the design was to create an interactive system that visually responds to changes in the sand
      surface.
    </p>
    <br />

    <h4>System Architecture Overview</h4>
    <p>
      The core components include the Kinect 1414 depth sensor, a Raspberry Pi 4, a vertically-mounted projector, and
      physical GPIO buttons on a TFT for control.
      The Kinect captures a live 480x640 stream of depth data which is sent to the Raspberry Pi via USB 3.0.
      The Raspberry Pi processes this depth data and generates a colorized image representing terrain elevation, which
      is then projected directly onto the sandbox.
      GPIO buttons connected to the Pi allow users to start and stop the visualization system.
    </p>
    <br />

    <h4>Hardware Design</h4>
    <p>
      Sensors & Processing: The Xbox 360 Kinect 1414 serves as the depth sensor, interfacing directly with the Raspberry
      Pi 4 over USB 3.0. The Kinect provides a continuous stream of z-values corresponding to the depth of points within
      its
      field of view.
    </p>
    <br>
    <p>
      Projection Setup: A standard overhead projector, provided by Professor Skovira, is mounted above the sandbox and
      aligned vertically to ensure proper projection coverage and minimize distortion.
    </p>
    <br>
    <p>
      GPIO Controls: GPIO buttons exposed by the TFT are accessable by the Raspberry Pi. The GPIO pins are used for
      starting and
      stopping the system. These allow the user to initiate or terminate the program without using a keyboard and mouse
      or SSH interface.
    </p>
    <br />

    <h4>Software Architecture</h4>
    <p>
      The system software is implemented using a combination of C and Python, leveraging the strengths of each language:
    </p>
    <br>
    <p>
      C Code: Handles all performance-critical tasks such as depth data acquisition and color mapping. This choice was
      made to improve real-time responsiveness given the Raspberry Pi’s limited processing power. We used the
      libfreenect
      library to utilize all four cores on the Pi and get the depth data from the Kinect efficiently. This allowed for
      the real time performance that is seen in our demo.
    </p>
    <br>
    <p>
      Python Script: Manages GPIO input and user interaction. A Python loop listens for GPIO button presses and controls
      the lifecycle of the C-based visualization subprocess.
    </p>
    <br />

    <h4>Data Processing Pipeline</h4>
    <p>
      Once the system is initialized via the start button:
    </p>
    <p>
      1) The Kinect begins streaming depth data.
    </p>
    <br>
    <p>
      2) The Kinect device context <code>freenect_context</code> is initialized and it opens
      <code>freenect_device</code>.
    </p>

    <details
      style="margin-top: 20px; background: #fff; border-radius: 10px; box-shadow: 0 4px 10px rgba(0,0,0,0.08); overflow: hidden; transition: all 0.3s ease;">
      <summary
        style="cursor: pointer; font-weight: 600; padding: 12px 16px; background: linear-gradient(135deg, #ff9999, #ff4d4d); color: white; font-size: 1rem;">
        View Code Block
      </summary>
      <pre
        style="margin: 0; padding: 16px; background-color: #f9f9f9; font-size: 0.95rem; line-height: 1.5; overflow-x: auto;">
    <code style="color: #333;">
    if (freenect_init(&f_ctx, NULL) &lt; 0) {
        printf("Freenect_Init Not Working\n");
        return -1;
    }
    
    if (freenect_open_device(f_ctx, &f_dev, 0) &lt; 0) {
        printf("Freenect Open Device Not Working\n");
        return -1;
    }
    
    if (init_sdl() &lt; 0) {
        return -1;
    }
    </code>
      </pre>
    </details>
    <br>
    <p>
      3) The SDL2 window, renderer, and texture are initialized for displaying
      the depth data. The function init_sdl will create a window
      called "Kinect Depth Viewer" with dimensions 1480x1080. Then it
      will create a renderer and a texture for rendering depth data
      using RGB24 pixel format of dimensions 480x640.
    </p>
    <details
      style="margin-top: 20px; background: #fff; border-radius: 10px; box-shadow: 0 4px 10px rgba(0,0,0,0.08); overflow: hidden; transition: all 0.3s ease;">
      <summary
        style="cursor: pointer; font-weight: 600; padding: 12px 16px; background: linear-gradient(135deg, #ff9999, #ff4d4d); color: white; font-size: 1rem;">
        View Code Block
      </summary>
      <pre
        style="margin: 0; padding: 16px; background-color: #f9f9f9; font-size: 0.95rem; line-height: 1.5; overflow-x: auto;">
  <code style="color: #333;">
    int init_sdl() {
      if (SDL_Init(SDL_INIT_VIDEO) < 0) {
          fprintf(stderr, "SDL Init Not Working: %s\n", SDL_GetError());
          return -1;
      }
  
      window = SDL_CreateWindow("Kinect Depth Viewer", 500, SDL_WINDOWPOS_UNDEFINED, 1480, 1080, 0);
      renderer = SDL_CreateRenderer(window, -1, SDL_RENDERER_ACCELERATED);
      texture = SDL_CreateTexture(renderer, SDL_PIXELFORMAT_RGB24, SDL_TEXTUREACCESS_STREAMING, WIDTH, HEIGHT);
  
      if (!window || !renderer || !texture) {
          fprintf(stderr, "SDL Not Working\n");
          return -1;
      }
  
      return 0;
  }
  </code>
    </pre>
    </details>
    <br>
    <p>
      4) Next we used the depth callback function using freenect_set_depth_callback
      to call depth_cb. This receives the depth data from the Kinect device and
      processes each pixel.
    </p>
    <br>
    <p>
      5) Each depth value is checked to be within the range 1100 to 1700 and
      then is normalized. This normalized value is mapped to RGB colors
      and assigns those RGB values to the corresponding pixel in the texture.
      If the value is out of range then the color is assigned to be grey. Based on the orientation of the projector and
      kinect, we had to flip the image 180 degrees as well.
    </p>
    <details
      style="margin-top: 20px; background: #fff; border-radius: 10px; box-shadow: 0 4px 10px rgba(0,0,0,0.08); overflow: hidden; transition: all 0.3s ease;">
      <summary
        style="cursor: pointer; font-weight: 600; padding: 12px 16px; background: linear-gradient(135deg, #ff9999, #ff4d4d); color: white; font-size: 1rem;">
        View Code Block
      </summary>
      <pre
        style="margin: 0; padding: 16px; background-color: #f9f9f9; font-size: 0.95rem; line-height: 1.5; overflow-x: auto;">
  <code style="color: #333;">
    void depth_cb(freenect_device *dev, void *depth, uint32_t timestamp){
      uint16_t *d = (uint16_t*)depth;
      unsigned char rgb[WIDTH * HEIGHT * 3];
  
      for (int y = 0; y < HEIGHT; ++y) {
          for (int x = 0; x < WIDTH; ++x) {
              uint16_t v = d[y * WIDTH + x];
              int index = (y * WIDTH + x) * 3;
  
              if (v >= 1100 && v <= 1700) {
                  float norm = 1.0f - (float)(v - 1300) / 100.0f; 
                  float r = fminf(fmaxf(1.5f - fabsf(4.0f * norm - 3.0f), 0.0f), 1.0f);
                  float g = fminf(fmaxf(1.5f - fabsf(4.0f * norm - 2.0f), 0.0f), 1.0f);
                  float b = fminf(fmaxf(1.5f - fabsf(4.0f * norm - 1.0f), 0.0f), 1.0f);
  
                  rgb[index + 0] = (uint8_t)(r * 255);
                  rgb[index + 1] = (uint8_t)(g * 255);
                  rgb[index + 2] = (uint8_t)(b * 255);
              } else {
                  rgb[index + 0] = 64;
                  rgb[index + 1] = 0;
                  rgb[index + 2] = 0;
              }
          }
      }
  
      SDL_UpdateTexture(texture, NULL, rgb, WIDTH * 3);
      SDL_RenderClear(renderer);
  
      SDL_Rect src_rect = {160, 120, 320, 240};
  
      SDL_Rect dst_rect = {0, 0, 1480, 1080};
  
      SDL_RenderCopyEx(renderer, texture, &src_rect, &dst_rect, 0, NULL, SDL_FLIP_HORIZONTAL | SDL_FLIP_VERTICAL);
      SDL_RenderPresent(renderer);
  }
  </code>
    </pre>
    </details>
    <br>
    <p>
      6) The final color-mapped image is sent to the projector, which overlays the visual representation onto the sand.
    </p>
    <br>
    <p>
      This loop repeats continuously, ensuring real-time updates as users manipulate the sand.
    </p>
    <br />

    <h4>Projection Mapping and Calibration</h4>
    <p>
      Projection alignment was a key part of the design process.
      Our sandbox has a square shape, while the camera feed and image output are rectangular.
      When booting from the Pi, we had to manually adjust the height and angle of the projector to ensure that the
      projected image correctly covered
      the sandbox area. This could simply be fixed by changing the mount to move a little forward and to the right.
      However, when running it from our computers, we could provide a digital offset to ensure accurate rendering.
      The depth range was also calibrated to match the typical height variations achievable within the sandbox.
    </p>
    <br />

    <h4>Real-Time Optimization</h4>
    <p>
      Given the limited computational resources of the Raspberry Pi, we prioritized efficiency:
    </p>
    <br>
    <p>
      All computationally intensive tasks, especially per-frame depth processing and color mapping, were implemented
      in
      C.
    </p>
    <br>
    <p>
      Python was used only where performance was not critical (GPIO control).
    </p>
    <br />

    <h4>Challenges and Solutions</h4>
    <p>
      Performance Bottlenecks: To enable real time performance, we both utilized the libfreenect library to use all 4
      of
      the
      Raspberry Pi's cores. In addition, we found that the Lab 4 kernel removed certain functionalities
      that were necessary for high performance. As a result, the Lab 3 kernel had files that
      enhanced our performance that were previously removed from the Lab 4 kernel.
    </p>
    <br>
    <p>
      Projection Alignment:
      On the computer, we could just set an offset to accurately map onto the sandbox. However, when booting from
      the Raspberry Pi, we had to make physical adjustments to the
      projector in order to try to align our projection to the sand without having an offset.
    </p>
    <br>
    <p>
      GPIO Responsiveness:
      Handling button presses with Python's GPIO library worked reliably after implementing and
      ensuring the subprocess management was clean. We were originally going to use touchscreen button functionality but
      it did not originally work with the Lab 4 kernel which is why we had swapped to the Lab 3 kernel. When doing
      testing for the TFT touchscreen button functionality, we were unable to spawn two windows (one on the TFT and one
      through the Projector) at the same time which
      is why we took the GPIO button approach.
    </p>
    <br>
    <p>
      Boot From Start:
      We found that we had issues when using Crontab in order to automate our system as everything we had tried, even
      using direct path names resulted in nothing working. We eventually swapped from using Crontab to using bashrc
      which
      worked perfectly. With this though, we had lost some fuctionality where the window would spawn off center but this
      could be fixed mannually.
    </p>
  </section>

  <section id="Installation Guide"
    style="background-color: #f9f9f9; padding: 40px 20px; border-radius: 12px; box-shadow: 0 4px 8px rgba(0,0,0,0.05); margin: 40px auto; max-width: 900px;">
    <h2 style="text-align: center; color: #2c3e50; margin-bottom: 25px;">Installation Guide</h2>
    <p style="font-size: 17px; color: #333; line-height: 1.6;">
      When working on this project, some small flaws we ran into that we would either like to address or improve are as
      follows:
    </p>
    <br>
    <ol style="text-align: left; padding-left: 20px; font-size: 16px; color: #444; line-height: 1.7;">
      <li>
        <span style="font-weight: bold; text-decoration: underline;">Start with the Lab 3 Kernel</span>:
        #Todo
      </li>
      <br>
      <li>
        <span style="font-weight: bold; text-decoration: underline;">Install Dependencies</span>:
      </li>
      <br>
      <li>
        <span style="font-weight: bold; text-decoration: underline;">Downloading OpenKinect's Libfreenect</span>:
        #Todo
      </li>
      <br>
      <li>
        <span style="font-weight: bold; text-decoration: underline;">Building Enviorment</span>:
        #Todo
      </li>
      <br>
      <li>
        <span style="font-weight: bold; text-decoration: underline;">Using Cython for Bindings and Wrappers</span>:
        #Todo
      </li>
      <br>
      <li>
        <span style="font-weight: bold; text-decoration: underline;">Setup and Install</span>:
        #Todo
      </li>
    </ol>
  </section>


  <section id="Testing">
    <h2>Testing</h2>
    <p>
      For our testing, we broke down the project into several components.
      First, we had to get the depth sensors working. For that we tested out
      several libraries where we ended up doing the project through libfreenect, an open source Linux library for the
      Xbox 360 Kinect.
      We then tried doing basic rendering of the scene by
      setting a threshold value and setting all values below that value to red
      and all values above it to blue after successfully being able to read depth data. After confirming and getting
      that working
      we then moved on to calibrating the projector from the computer.
      This was done to make sure we could properly align the colors with
      the map and make sure that the depth sensor and projector could be aligned together.
      Next, we then debugged implementing real time functionality.
      The libfreenect library allowed us to use all four cores on the Pi
      and interestingly, using the kernel from Lab 3 as opposed to Lab 4
      also sped up performance significantly. Lastly, we then just implemented
      GPIO button as we had regained functionality from the PiTFT when swapping to the Lab 3 kernel. We used this
      functionality so that we could use
      the Pi to initialize and
      terminate the project from boot.
    </p>
  </section>

  <section id="Result">
    <h2>Result</h2>
    <h4>System Performance and Accuracy</h4>
    <p>
      We were able to implement real-time depth mapping given that the Kinect
      sensor captured the depth data and the libfreenect library enabled
      the system to generate accurate topographic maps in real-time.
      In addition, our use of C for all time critical components of
      the program enabled its high performance. Lastly,
      implementing an offset on the computer allowed for accurate
      projection alignment. However, when booting from the Pi we
      had to make manual adjustments to try to improve its accuracy. As for the development of our code over time, some
      photos attached below highlight our adjustment and progression over time to meet the standards for this project we
      desired.
    </p>
    <div style="display: flex; justify-content: center; gap: 20px; flex-wrap: wrap; margin-top: 30px;">
      <div style="text-align: center;">
        <img src="photos/iteration1.png" alt="Iteration 1"
          style="width: 260px; border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
        <p style="margin-top: 8px; font-size: 0.95rem;">Iteration 1: Initial setup and raw depth mapping</p>
      </div>
      <div style="text-align: center;">
        <img src="photos/iteration2.png" alt="Iteration 2"
          style="width: 260px; border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
        <p style="margin-top: 8px; font-size: 0.95rem;">Iteration 2: Improved alignment and color mapping</p>
      </div>
      <div style="text-align: center;">
        <img src="photos/iteration3.png" alt="Iteration 3"
          style="width: 260px; border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
        <p style="margin-top: 8px; font-size: 0.95rem;">Iteration 3: Final setup with real-time topography</p>
      </div>
    </div>

    <br>
    <h4>User Interaction and Engagement</h4>
    <p>
      Users were able to engage with our project by actively shaping the
      sand in the sandbox to create various topographic features.
      They were able to observe immediate changes in the projected map
      that reflected the changes that they had created in the sand. Through visually tesitng, we were able to determine
      its effectivness and accuracy.
    </p>
    <br>
    <h4>Challenges Encountered</h4>
    <p>
      We faced several difficult challenges. Primarily amongst it was
      determining how to interface with the XBox 360 Kinect. In addition,
      how to process the data at real-time speeds was another challenge.
      Lastly, attempting to calibrate the projector as well as building
      the physical sandbox were additional challenges we had to overcome.
    </p>
    <br>
    <h4>Summary</h4>
    <p>
      Overall, you can see the results of our project shared below
      with an image of us together next to the sandbox as well as a
      video of us testing it out.
    </p>

    <div
      style="display: flex; justify-content: center; gap: 20px; flex-wrap: wrap; align-items: center; margin-top: 20px;">

      <img src="photos/IMG_4871.jpeg" alt="Team with Sandbox"
        style="width: 400px; height: 700px; object-fit: cover; object-position: left; border-radius: 10px; box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);">


      <video controls
        style="width: 400px; height: 700px; object-fit: cover; border-radius: 10px; box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);">
        <source src="photos/IMG_4872.mp4" type="video/mp4">
      </video>
    </div>
  </section>

  <section id="Conclusion">
    <h2>Conclusion</h2>
    <p>
      In completing this project, we were able to successfully create a topographic sandbox on a linux based operating
      system through using a depth camera from an XBox 360 Kinect and a Raspberry Pi 4. Our final project helped us
      learn how to tailor a solution for an uncertain desing process, learn to adjust to the limitations of the
      hardware, all within a timely manner. We were able to create a close to real-time topographic map of the sandbox
      with minimal delay and utilization of multi-core to solve a hardware problem even though it was handled through a
      open source library. Also, as an Electrical and Computer Engineer and a Computer Scientist, we develoepd
      mechanical skills on assembly of a sturdy frame and mount for the Kinect and projector.
      <br>
      <br>
      Some mistakes that we made along the way included some mistakes on the mounting of the projector resulting in some
      off center behavior. Also, when working in the Lab 4 kernel, we ran into difficulties with getting certain
      librarbies to work that we needed including Pygame and envtest. When prepping, we should have verified that these
      we including before realizing later on, resulting in a swap to a older kernel close to our due date. Lastly, by
      playing around with our operating system for boot last minute, we had made some mistakes to the system that
      resulted in our "startx" command not working as intended, though the project still worked. With that being said,
      our biggest takeaway is to always test our system step by step along with keeping a backup of the system in case
      things go wrong!
    </p>
  </section>

  <section id="Future Work"
    style="background-color: #f9f9f9; padding: 40px 20px; border-radius: 12px; box-shadow: 0 4px 8px rgba(0,0,0,0.05); margin: 40px auto; max-width: 900px;">
    <h2 style="text-align: center; color: #2c3e50; margin-bottom: 25px;">Future Work</h2>
    <p style="font-size: 17px; color: #333; line-height: 1.6;">
      When working on this project, some small flaws we ran into that we would either like to address or improve are as
      follows:
    </p>
    <br>
    <ol style="text-align: left; padding-left: 20px; font-size: 16px; color: #444; line-height: 1.7;">
      <li>
        <span style="font-weight: bold; text-decoration: underline;">Centering the projector to the sandbox</span>:
        Starting our program from boot via <code>.bashrc</code> had side effects that caused the window to spawn
        off-center. This slightly shifted the projection upward and to the right. We could fix this by physically
        adjusting the projector mount.
      </li>
      <li>
        <span style="font-weight: bold; text-decoration: underline;">Adding touchscreen buttons</span>: Initially, we
        couldn't use the PiTFT with our Lab 4 kernel, which lacked Pygame support. After switching to the Lab 3 kernel,
        the TFT worked, but due to time constraints, we used GPIO buttons instead of touchscreen GUI buttons. Adding a
        touchscreen interface would improve usability.
      </li>
      <li>
        <span style="font-weight: bold; text-decoration: underline;">Deeper color mapping</span>: We implemented a color
        range from red to blue, but additional enhancements could include gradient rings for more distinct terrain lines
        and a richer color palette.
      </li>
    </ol>
  </section>

  <section id="Budget">
    <h2>Budget</h2>
    <p>The materials for our project revolved around making use of any unused materials lying around within the ECE
      Department and the loading doc. In the short section below, we will describe the materials used, their purpose and
      where they were gotten.
      <br>
      <br>
      In ECE 5725, the main device utilized is a Raspberry Pi V4 along with a 16 GB MicroSD card, a 15W USB-C for power,
      and a resistive PiTFT that mounts on the Raspberry Pi V4 Pins. The rest of the items listed are used for our
      specific Topographic Map Sandbox project.
      <br>
      <br>
      We developed a frame and mount from wood, tape, and screws along with a cardboard bottom to hold the sand. This in
      total would cost you about $12, however we made us of materials left over from the loading dock, along with some
      extra materials Professor Skovira had around. We had purchased 100 lbs of play sand from Home Depot but only used
      40lbs for our project, resulting in about $6.39 worth of sand used. The XBox 360 was purchased off of Ebay with
      the needed wires (power and USB-3.0) for $10.99. For the last of the materials that made up this project, we used
      a small table which we had borrowed from Professor Skovira along with a projector Cornell IT was not using.
      <br>
      <br>
      With this, our total price was about $115.38 dollars. If we were to exclude all of the provided materials
      (Raspberry Pi V4, 16 GB MicroSD card, 15W USB-C power supply, resistive PiTFT, table and projector), the total
      cost of the project would be, about $29.38.
    </p>
    <div
      style="background-color: white; padding: 20px; margin-top: 20px; width: 80%; max-width: 800px; margin: 0 auto; border-radius: 10px; box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1); text-align: left;">
      <h3 style="color: #007BFF; margin-bottom: 20px;">Materials</h3>
      <table style="width: 100%; border-collapse: collapse; margin-bottom: 20px;">
        <tr>
          <th style="border: 1px solid #ddd; padding: 10px; text-align: left; background-color: #007BFF; color: white;">
            Component</th>
          <th style="border: 1px solid #ddd; padding: 10px; text-align: left; background-color: #007BFF; color: white;">
            Estimate (USD)</th>
        </tr>
        <tr>
          <td style="border: 1px solid #ddd; padding: 10px;">Raspberry Pi V4</td>
          <td style="border: 1px solid #ddd; padding: 10px;">$35</td>
        </tr>
        <tr>
          <td style="border: 1px solid #ddd; padding: 10px;">16 GB MicroSD Card</td>
          <td style="border: 1px solid #ddd; padding: 10px;">$8</td>
        </tr>
        <tr>
          <td style="border: 1px solid #ddd; padding: 10px;">15W USB-C Power Supply Cable</td>
          <td style="border: 1px solid #ddd; padding: 10px;">$8</td>
        </tr>
        <tr>
          <td style="border: 1px solid #ddd; padding: 10px;">Resistive Touch PiTFT (320x240) 2.8"</td>
          <td style="border: 1px solid #ddd; padding: 10px;">$35</td>
        </tr>
        <tr>
          <td style="border: 1px solid #ddd; padding: 10px;">Frame (Wood + Tape + Cardboard) + Screws</td>
          <td style="border: 1px solid #ddd; padding: 10px;">$12</td>
        </tr>
        <tr>
          <td style="border: 1px solid #ddd; padding: 10px;">Sand (40 lbs)</td>
          <td style="border: 1px solid #ddd; padding: 10px;">$6.39</td>
        </tr>
        <tr>
          <td style="border: 1px solid #ddd; padding: 10px;">Xbox 360 Kinect Model 1414</td>
          <td style="border: 1px solid #ddd; padding: 10px;">$10.99</td>
        </tr>
        <tr>
          <td style="border: 1px solid #ddd; padding: 10px;">Table (Borrowed)</td>
          <td style="border: 1px solid #ddd; padding: 10px;">$0</td>
        </tr>
        <tr>
          <td style="border: 1px solid #ddd; padding: 10px;">Projector (From IT)</td>
          <td style="border: 1px solid #ddd; padding: 10px;">$0</td>
        </tr>
        <tr style="font-weight: bold; background-color: #e0e0e0;">
          <td style="border: 1px solid #ddd; padding: 10px;">Total Cost Estimate</td>
          <td style="border: 1px solid #ddd; padding: 10px;">$115.38</td>
        </tr>
      </table>
    </div>
  </section>

  <section id="The Team">
    <h2>The Team</h2>
    <div style="display: flex; justify-content: center; gap: 40px; flex-wrap: wrap; margin-top: 30px;">
      <div
        style="background: white; padding: 20px; border-radius: 16px; box-shadow: 0 4px 12px rgba(0,0,0,0.1); width: 250px; text-align: center;">
        <img src="photos/the_team_photos/" alt="Member 1"
          style="width: 100%; border-radius: 12px; object-fit: cover; height: 300px; margin-bottom: 15px;">
        <h3 style="margin-bottom: 5px;">George Maidhof (gpm58)</h3>
        <p style="color: #777;">Electrical and Computer Engineering</p>
      </div>

      <div
        style="background: white; padding: 20px; border-radius: 16px; box-shadow: 0 4px 12px rgba(0,0,0,0.1); width: 250px; text-align: center;">
        <img src="photos/the_team_photos/" alt="Member 2"
          style="width: 100%; border-radius: 12px; object-fit: cover; height: 300px; margin-bottom: 15px;">
        <h3 style="margin-bottom: 5px;">Giorgi Berndt (gb449)</h3>
        <p style="color: #777;">Computer Science</p>
      </div>
    </div>
  </section>

  <section id="References">
    <h2>References</h2>
    <p>
      [1] C. Beals, “How to Build an Augmented Reality Sandbox,” bealsscience. Accessed: May 10, 2025. [Online].
      Available: https://www.bealsscience.com/post/2017/06/07/augmented-reality-sandbox-will-blow-your-mind
      <br />
      [2] “OpenKinect.” Accessed: May 10, 2025. [Online]. Available: https://github.com/OpenKinect
      <br />
      [3] “SDL library in C/C++ with examples,” GeeksforGeeks. Accessed: May 10, 2025. [Online]. Available:
      https://www.geeksforgeeks.org/sdl-library-in-c-c-with-examples/
      <br />
      [4] J. Skovira, “ECE 5725 Lab 1,” 2025. Lab 1_Spring2025_v2.pdf. Accessed: May 10, 2025. [Online].
      <br />
      [5] J. Skovira, “ECE 5725 Lab 3,” 2025. Lab 3_Spring2025_v2.pdf. Accessed: May 10, 2025. [Online].
    </p>
  </section>

  <section id="Distribution">
    <h2>Distribution</h2>
    <p>
      Given that George Maidhof is an ECE Major and Giorgi Berndt is a CS Major,
      George spearheaded the work on the hardware side while Giorgi focused on
      the software side. Given Giorgi was traveling some of the last week prior to the
      competition, George ended up spending more time in the lab
      so Giorgi made up for it by authoring most of the work on the website.
    </p>
  </section>

  <section id="The Code Listing">
    <h2>The Code Listing</h2>
    <p>
    <details
      style="margin-top: 20px; background: #fff; border-radius: 10px; box-shadow: 0 4px 10px rgba(0,0,0,0.08); overflow: hidden; transition: all 0.3s ease;">
      <summary
        style="cursor: pointer; font-weight: 600; padding: 12px 16px; background: linear-gradient(135deg, #ff9999, #ff4d4d); color: white; font-size: 1rem;">
        View Code Block
      </summary>
      <pre
        style="margin: 0; padding: 16px; background-color: #f9f9f9; font-size: 0.95rem; line-height: 1.5; overflow-x: auto;">
  <code style="color: #333;">
 
  </code>
    </pre>
    </details>
    </p>
  </section>

  <!-- Scroll Effects Script -->
  <script>
    const handlesLogos = document.querySelector('.handles-logos');

    function revealOnScroll() {
      const triggerBottom = window.innerHeight * 0.85;
      const boxTop = handlesLogos.getBoundingClientRect().top;
      if (boxTop < triggerBottom) {
        handlesLogos.classList.add('visible');
      }
    }

    function highlightNav() {
      const sections = document.querySelectorAll("section");
      const navLinks = document.querySelectorAll("nav a");

      let current = "home";
      sections.forEach((section) => {
        const top = window.scrollY + 100;
        const offset = section.offsetTop;
        if (top >= offset) {
          current = section.getAttribute("id");
        }
      });

      navLinks.forEach((link) => {
        link.classList.remove("active");
        if (link.getAttribute("href") === `#${current}`) {
          link.classList.add("active");
        }
      });
    }

    window.addEventListener("scroll", () => {
      revealOnScroll();
      highlightNav();
    });

    window.addEventListener("load", () => {
      revealOnScroll();
      highlightNav();
    });
  </script>

</body>

</html>